{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "import folium\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='silkeh', api_key='GwBAmaelgKfgkrmuL691')\n",
    "\n",
    "separator = '\\t'\n",
    "#Eva\n",
    "#filepath = 'D:/Workspace/_DataMining/DataSets'\n",
    "#Silke\n",
    "filepath = 'C:/Users/Silke/Documents/GitHub/DataMiningAP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB\n",
    "## Creation of RDD's and DF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+-------+---------+-------+--------------------+\n",
      "|   tconst|titleType|        primaryTitle|isAdult|startYear|endYear|              genres|\n",
      "+---------+---------+--------------------+-------+---------+-------+--------------------+\n",
      "|tt0000001|    short|          Carmencita|      0|     1894|     \\N|   Documentary,Short|\n",
      "|tt0000002|    short|Le clown et ses c...|      0|     1892|     \\N|     Animation,Short|\n",
      "|tt0000003|    short|      Pauvre Pierrot|      0|     1892|     \\N|Animation,Comedy,...|\n",
      "|tt0000004|    short|         Un bon bock|      0|     1892|     \\N|     Animation,Short|\n",
      "|tt0000005|    short|    Blacksmith Scene|      0|     1893|     \\N|        Comedy,Short|\n",
      "+---------+---------+--------------------+-------+---------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.BASICS\n",
    "#tconst, titleType, primaryTitle, originalTitle, isAdult, startYear, endYear, runtimeMinutes, genres\n",
    "titleBasics_data = sc.textFile(filepath + '/IMDB/titleBasics.tsv')\n",
    "titleBasics_rdd = titleBasics_data.filter(lambda l: 'primaryTitle' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "tbFields = []\n",
    "tbFields.append(StructField('tconst', StringType(), True))\n",
    "tbFields.append(StructField('titleType', StringType(), True))\n",
    "tbFields.append(StructField('primaryTitle', StringType(), True))\n",
    "tbFields.append(StructField('originalTitle', StringType(), True))\n",
    "tbFields.append(StructField('isAdult', StringType(), True))\n",
    "tbFields.append(StructField('startYear', StringType(), True))\n",
    "tbFields.append(StructField('endYear', StringType(), True))\n",
    "tbFields.append(StructField('runtimeMinutes', StringType(), True))\n",
    "tbFields.append(StructField('genres', StringType(), True))                           \n",
    "\n",
    "tbSchema = StructType(tbFields)\n",
    "\n",
    "#create df\n",
    "titleBasics_df = sqlContext.createDataFrame(titleBasics_rdd, tbSchema)\n",
    "\n",
    "#clean data\n",
    "titleBasics_df = titleBasics_df.drop('originalTitle', 'runtimeMinutes').sort('tconst', ascending=True)\n",
    "titleBasics_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+--------+-----------+--------------------+---------------+\n",
      "|  titleId|ordering|               title|region|language|      types|          attributes|isOriginalTitle|\n",
      "+---------+--------+--------------------+------+--------+-----------+--------------------+---------------+\n",
      "|tt0000001|       3|          Carmencita|    US|      \\N|         \\N|                  \\N|              0|\n",
      "|tt0000002|       5|The Clown and His...|    US|      \\N|         \\N|literal English t...|              0|\n",
      "|tt0000005|       1| Blacksmithing Scene|    US|      \\N|alternative|                  \\N|              0|\n",
      "|tt0000006|       3|   Chinese Opium Den|    US|      \\N|         \\N|                  \\N|              0|\n",
      "|tt0000007|       1|Corbett and Court...|    US|      \\N|         \\N|                  \\N|              0|\n",
      "+---------+--------+--------------------+------+--------+-----------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.AKAS\n",
    "#tconst, ordering, title, region, language, types, attributes, isOriginalTitle\n",
    "titleAkas_data = sc.textFile(filepathEva + '/IMDB/titleAkas.tsv')\n",
    "titleAkas_rdd = titleAkas_data.filter(lambda l: 'ordering' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "taFields = []\n",
    "taFields.append(StructField('titleId', StringType(), True))\n",
    "taFields.append(StructField('ordering', StringType(), True))\n",
    "taFields.append(StructField('title', StringType(), True))\n",
    "taFields.append(StructField('region', StringType(), True))\n",
    "taFields.append(StructField('language', StringType(), True))\n",
    "taFields.append(StructField('types', StringType(), True))\n",
    "taFields.append(StructField('attributes', StringType(), True))\n",
    "taFields.append(StructField('isOriginalTitle', StringType(), True))                       \n",
    "\n",
    "taSchema = StructType(taFields)\n",
    "\n",
    "#create df\n",
    "titleAkas_df= sqlContext.createDataFrame(titleAkas_rdd, taSchema)\n",
    "\n",
    "#clean data\n",
    "titleAkas_df = titleAkas_df.filter(titleAkas_df.region =='US')\n",
    "titleAkas_df = titleAkas_df.dropDuplicates(['titleId']).sort('titleId', ascending=True)\n",
    "\n",
    "titleAkas_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+--------+--------------+\n",
      "|   tconst|ordering|   nconst|category|    characters|\n",
      "+---------+--------+---------+--------+--------------+\n",
      "|tt0000005|       2|nm0653042|   actor| [\"Assistant\"]|\n",
      "|tt0000005|       1|nm0443482|   actor|[\"Blacksmith\"]|\n",
      "+---------+--------+---------+--------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.PRINCIPALS\n",
    "#tconst, ordering, nconst, category, job, characters\n",
    "titlePrincipals_data = sc.textFile(filepathEva + '/IMDB/titlePrincipals.tsv')\n",
    "titlePrincipals_rdd = titlePrincipals_data.filter(lambda l: 'ordering' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "tpFields = []\n",
    "tpFields.append(StructField('tconst', StringType(), True))\n",
    "tpFields.append(StructField('ordering', StringType(), True))\n",
    "tpFields.append(StructField('nconst', StringType(), True))\n",
    "tpFields.append(StructField('category', StringType(), True))\n",
    "tpFields.append(StructField('job', StringType(), True))\n",
    "tpFields.append(StructField('characters', StringType(), True))                     \n",
    "\n",
    "tpSchema = StructType(tpFields)\n",
    "\n",
    "#create df\n",
    "titlePrincipals_df = sqlContext.createDataFrame(titlePrincipals_rdd, tpSchema)\n",
    "\n",
    "#clean data\n",
    "titlePrincipals_df = titlePrincipals_df.filter(titlePrincipals_df.category.contains(\"actor\") | titlePrincipals_df.category.contains(\"actress\"))\n",
    "titlePrincipals_df = titlePrincipals_df.drop('job').sort('tconst', ascending=True)\n",
    "\n",
    "titlePrincipals_df.show(2, truncate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------+\n",
      "|   tconst|averageRating|numVotes|\n",
      "+---------+-------------+--------+\n",
      "|tt0000001|          5.8|    1416|\n",
      "|tt0000002|          6.4|     167|\n",
      "+---------+-------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.RATINGS\n",
    "#tconst, averageRating, numVotes\n",
    "titleRatings_data = sc.textFile(filepathEva + '/IMDB/titleRatings.tsv')\n",
    "titleRatings_rdd = titleRatings_data.filter(lambda l: 'averageRating' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "trFields = []\n",
    "trFields.append(StructField('tconst', StringType(), True))\n",
    "trFields.append(StructField('averageRating', StringType(), True))\n",
    "trFields.append(StructField('numVotes', StringType(), True))                    \n",
    "\n",
    "trSchema = StructType(trFields)\n",
    "\n",
    "#create df\n",
    "titleRatings_df= sqlContext.createDataFrame(titleRatings_rdd, trSchema)\n",
    "\n",
    "titleRatings_df.show(2, truncate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------------+-------------+\n",
      "|   tconst|parentTconst|seasonNumber|episodeNumber|\n",
      "+---------+------------+------------+-------------+\n",
      "|tt0041951|   tt0041038|           1|            9|\n",
      "|tt0042816|   tt0989125|           1|           17|\n",
      "+---------+------------+------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.EPISODE\n",
    "#tconst, parentTconst, seasonNumber, episodeNumber\n",
    "titleEpisode_data = sc.textFile(filepathEva + '/IMDB/titleEpisode.tsv')\n",
    "titleEpisode_rdd = titleEpisode_data.filter(lambda l: 'seasonNumber' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "teFields = []\n",
    "teFields.append(StructField('tconst', StringType(), True))\n",
    "teFields.append(StructField('parentTconst', StringType(), True))\n",
    "teFields.append(StructField('seasonNumber', StringType(), True))\n",
    "teFields.append(StructField('episodeNumber', StringType(), True))                    \n",
    "\n",
    "teSchema = StructType(teFields)\n",
    "\n",
    "#create df\n",
    "titleEpisode_df= sqlContext.createDataFrame(titleEpisode_rdd, teSchema)\n",
    "\n",
    "titleEpisode_df.show(2, truncate = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+---------+--------------------+\n",
      "|   nconst|    primaryName|deathYear|   primaryProfession|\n",
      "+---------+---------------+---------+--------------------+\n",
      "|nm0000001|   Fred Astaire|     1987|soundtrack,actor,...|\n",
      "|nm0000002|  Lauren Bacall|     2014|  actress,soundtrack|\n",
      "|nm0000003|Brigitte Bardot|       \\N|actress,soundtrac...|\n",
      "|nm0000004|   John Belushi|     1982|actor,writer,soun...|\n",
      "|nm0000005| Ingmar Bergman|     2007|writer,director,a...|\n",
      "+---------+---------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NAME.BASICS\n",
    "#nconst, primaryName, birthYear, deathYear, primaryProfession, knownForTitles\n",
    "nameBasics_data = sc.textFile(filepathEva + '/IMDB/nameBasics.tsv')\n",
    "nameBasics_rdd = nameBasics_data.filter(lambda l: 'primaryName' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "nmFields = []\n",
    "nmFields.append(StructField('nconst', StringType(), True))\n",
    "nmFields.append(StructField('primaryName', StringType(), True))\n",
    "nmFields.append(StructField('birthYear', StringType(), True))\n",
    "nmFields.append(StructField('deathYear', StringType(), True))\n",
    "nmFields.append(StructField('primaryProfession', StringType(), True))\n",
    "nmFields.append(StructField('knownForTitles', StringType(), True))\n",
    "\n",
    "nmSchema = StructType(nmFields)\n",
    "\n",
    "#create df\n",
    "nameBasics_df= sqlContext.createDataFrame(nameBasics_rdd, nmSchema)\n",
    "\n",
    "#clean data\n",
    "nameBasics_df = nameBasics_df.drop('birthYear', 'knownForTitles')\n",
    "nameBasics_df = nameBasics_df.filter(nameBasics_df.primaryProfession.contains(\"actor\")|nameBasics_df.primaryProfession.contains(\"actress\")).sort('nconst', ascending=True)\n",
    "\n",
    "nameBasics_df.show(5, truncate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join title.Basics and title.Akas and title.Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------+---------+---------+-------+--------------------+-------------+--------+\n",
      "|  titleId|               title|region|titleType|startYear|endYear|              genres|averageRating|numVotes|\n",
      "+---------+--------------------+------+---------+---------+-------+--------------------+-------------+--------+\n",
      "|tt0021617|   Arizona Territory|    US|    movie|     1950|     \\N|             Western|          5.4|      18|\n",
      "|tt0031603|Made in Germany -...|    US|    movie|     1957|     \\N|     Biography,Drama|          6.5|      13|\n",
      "|tt0035423|    Kate and Leopold|    US|    movie|     2001|     \\N|Comedy,Fantasy,Ro...|          6.4|   72053|\n",
      "+---------+--------------------+------+---------+---------+-------+--------------------+-------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Aliases\n",
    "Basics = titleBasics_df.alias('Basics')\n",
    "Akas = titleAkas_df.alias('Akas')\n",
    "Ratings = titleRatings_df.alias('Ratings')\n",
    "\n",
    "#join title.Basics to title.Akas\n",
    "AkasBasics = Akas.join(Basics, Akas.titleId == Basics.tconst, how='left')\n",
    "\n",
    "#clean data 1st join\n",
    "AkasBasics = AkasBasics.filter(AkasBasics.isAdult =='0')\n",
    "AkasBasics = AkasBasics.drop('ordering', 'language', 'types', \n",
    "                               'attributes', 'isOriginalTitle', 'tconst', \n",
    "                               'primaryTitle', 'isAdult')\n",
    "AkasBasics = AkasBasics.filter(AkasBasics.titleType.contains(\"movie\") | AkasBasics.titleType.contains(\"tvSeries\") | AkasBasics.titleType.contains(\"tvEpisode\"))\n",
    "AkasBasics = AkasBasics.filter(AkasBasics.startYear >='1950').sort('titleId', ascending=True)\n",
    "\n",
    "#join AkasBasics with title.Ratings\n",
    "titleABR = AkasBasics.join(Ratings, AkasBasics.titleId == Ratings.tconst, how='left').sort('titleId', ascending=True)\n",
    "\n",
    "#clean data 2nd join\n",
    "titleABR = titleABR.drop('tconst')\n",
    "\n",
    "titleABR.show(3, truncate = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BabyNames\n",
    "## RDD Creation\n",
    "### US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#US Baby Names\n",
    "#NationalNames.csv\n",
    "#Id,Name,Year,Gender,Count\n",
    "nationalname_rdd_init = (sc.textFile(filepath + '/us-baby-names/NationalNames.csv'))\n",
    "nationalname_rdd = nationalname_rdd_init.filter(lambda x: 'Gender' not in x)\n",
    "nationalname_rdd = nationalname_rdd.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State Baby Names\n",
    "#StateNames.csv\n",
    "#Id,Name,Year,Gender,State,Count\n",
    "full_statename_rdd_init = (sc.textFile(filepath + '/us-baby-names/StateNames.csv'))\n",
    "full_statename_rdd = full_statename_rdd_init.filter(lambda x: 'Gender' not in x).map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n",
    "us_states_abbreviations = list(us_states.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "## How many times does name x occur per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~silkeh/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#year = \"2005\"\n",
    "#nationalname_peryear_rdd = nationalname_rdd.filter(lambda x: x[2] == year)\n",
    "name = \"Arwen\"\n",
    "pername_nationalname_rdd = nationalname_rdd.filter(lambda x: x[1] == name)\n",
    "# Create a trace\n",
    "#print(nationalname_rdd.map(lambda x: int(x[4])).take(10))\n",
    "#print(nationalname_rdd.map(lambda x: int(x[2])).take(10))\n",
    "\n",
    "trace = go.Scatter(\n",
    "    x = pername_nationalname_rdd.map(lambda x: int(x[2])).collect(),\n",
    "    y = pername_nationalname_rdd.map(lambda x: int(x[4])).collect()\n",
    ")\n",
    "\n",
    "data = [trace]\n",
    "\n",
    "py.iplot(data, filename='basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
