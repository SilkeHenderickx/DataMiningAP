{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "import folium\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.widgets import GraphWidget\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='silkeh', api_key='GwBAmaelgKfgkrmuL691')\n",
    "\n",
    "separator = '\\t'\n",
    "#Eva\n",
    "#filepath = 'D:/Workspace/_DataMining/DataSets'\n",
    "#Silke\n",
    "filepath = 'C:/Users/Silke/Documents/GitHub/DataMiningAP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB\n",
    "## Creation of RDD's and DF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+-------+---------+-------+--------------------+\n",
      "|   tconst|titleType|        primaryTitle|isAdult|startYear|endYear|              genres|\n",
      "+---------+---------+--------------------+-------+---------+-------+--------------------+\n",
      "|tt0000001|    short|          Carmencita|      0|     1894|     \\N|   Documentary,Short|\n",
      "|tt0000002|    short|Le clown et ses c...|      0|     1892|     \\N|     Animation,Short|\n",
      "|tt0000003|    short|      Pauvre Pierrot|      0|     1892|     \\N|Animation,Comedy,...|\n",
      "|tt0000004|    short|         Un bon bock|      0|     1892|     \\N|     Animation,Short|\n",
      "|tt0000005|    short|    Blacksmith Scene|      0|     1893|     \\N|        Comedy,Short|\n",
      "+---------+---------+--------------------+-------+---------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.BASICS\n",
    "#tconst, titleType, primaryTitle, originalTitle, isAdult, startYear, endYear, runtimeMinutes, genres\n",
    "titleBasics_data = sc.textFile(filepath + '/IMDB/titleBasics.tsv')\n",
    "titleBasics_rdd = titleBasics_data.filter(lambda l: 'primaryTitle' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "tbFields = []\n",
    "tbFields.append(StructField('tconst', StringType(), True))\n",
    "tbFields.append(StructField('titleType', StringType(), True))\n",
    "tbFields.append(StructField('primaryTitle', StringType(), True))\n",
    "tbFields.append(StructField('originalTitle', StringType(), True))\n",
    "tbFields.append(StructField('isAdult', StringType(), True))\n",
    "tbFields.append(StructField('startYear', StringType(), True))\n",
    "tbFields.append(StructField('endYear', StringType(), True))\n",
    "tbFields.append(StructField('runtimeMinutes', StringType(), True))\n",
    "tbFields.append(StructField('genres', StringType(), True))                           \n",
    "\n",
    "tbSchema = StructType(tbFields)\n",
    "\n",
    "#create df\n",
    "titleBasics_df = sqlContext.createDataFrame(titleBasics_rdd, tbSchema)\n",
    "\n",
    "#clean data\n",
    "titleBasics_df = titleBasics_df.drop('originalTitle', 'runtimeMinutes').sort('tconst', ascending=True)\n",
    "titleBasics_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+--------+-----------+--------------------+---------------+\n",
      "|  titleId|ordering|               title|region|language|      types|          attributes|isOriginalTitle|\n",
      "+---------+--------+--------------------+------+--------+-----------+--------------------+---------------+\n",
      "|tt0000001|       3|          Carmencita|    US|      \\N|         \\N|                  \\N|              0|\n",
      "|tt0000002|       5|The Clown and His...|    US|      \\N|         \\N|literal English t...|              0|\n",
      "|tt0000005|       1| Blacksmithing Scene|    US|      \\N|alternative|                  \\N|              0|\n",
      "|tt0000006|       3|   Chinese Opium Den|    US|      \\N|         \\N|                  \\N|              0|\n",
      "|tt0000007|       1|Corbett and Court...|    US|      \\N|         \\N|                  \\N|              0|\n",
      "+---------+--------+--------------------+------+--------+-----------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.AKAS\n",
    "#tconst, ordering, title, region, language, types, attributes, isOriginalTitle\n",
    "titleAkas_data = sc.textFile(filepath + '/IMDB/titleAkas.tsv')\n",
    "titleAkas_rdd = titleAkas_data.filter(lambda l: 'ordering' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "taFields = []\n",
    "taFields.append(StructField('titleId', StringType(), True))\n",
    "taFields.append(StructField('ordering', StringType(), True))\n",
    "taFields.append(StructField('title', StringType(), True))\n",
    "taFields.append(StructField('region', StringType(), True))\n",
    "taFields.append(StructField('language', StringType(), True))\n",
    "taFields.append(StructField('types', StringType(), True))\n",
    "taFields.append(StructField('attributes', StringType(), True))\n",
    "taFields.append(StructField('isOriginalTitle', StringType(), True))                       \n",
    "\n",
    "taSchema = StructType(taFields)\n",
    "\n",
    "#create df\n",
    "titleAkas_df= sqlContext.createDataFrame(titleAkas_rdd, taSchema)\n",
    "\n",
    "#clean data\n",
    "titleAkas_df = titleAkas_df.filter(titleAkas_df.region =='US')\n",
    "titleAkas_df = titleAkas_df.dropDuplicates(['titleId']).sort('titleId', ascending=True)\n",
    "\n",
    "titleAkas_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+--------+--------------+\n",
      "|   tconst|ordering|   nconst|category|    characters|\n",
      "+---------+--------+---------+--------+--------------+\n",
      "|tt0000005|       2|nm0653042|   actor| [\"Assistant\"]|\n",
      "|tt0000005|       1|nm0443482|   actor|[\"Blacksmith\"]|\n",
      "+---------+--------+---------+--------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['tt0000005', '1', 'nm0443482', 'actor', '[\"Blacksmith\"]'],\n",
       " ['tt0000005', '2', 'nm0653042', 'actor', '[\"Assistant\"]'],\n",
       " ['tt0000008', '1', 'nm0653028', 'actor', '[\"Sneezing Man\"]'],\n",
       " ['tt0000009',\n",
       "  '1',\n",
       "  'nm0063086',\n",
       "  'actress',\n",
       "  '[\"Miss Geraldine Holbrook (Miss Jerry)\"]'],\n",
       " ['tt0000009', '2', 'nm0183823', 'actor', '[\"Mr. Hamilton\"]'],\n",
       " ['tt0000011', '1', 'nm3692297', 'actor', '[\"Acrobats\"]'],\n",
       " ['tt0000014', '1', 'nm0166380', 'actor', '[\"The Gardener\"]'],\n",
       " ['tt0000014', '2', 'nm0244989', 'actor', '[\"The Boy\"]'],\n",
       " ['tt0000017', '1', 'nm3691272', 'actor', '[\"The boy\"]'],\n",
       " ['tt0000017', '2', 'nm3692829', 'actress', '[\"The girl\"]']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TITLE.PRINCIPALS\n",
    "#tconst, ordering, nconst, category, job, characters\n",
    "titlePrincipals_data = sc.textFile(filepath + '/IMDB/titlePrincipals.tsv')\n",
    "titlePrincipals_rdd = titlePrincipals_data.filter(lambda l: 'ordering' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "tpFields = []\n",
    "tpFields.append(StructField('tconst', StringType(), True))\n",
    "tpFields.append(StructField('ordering', StringType(), True))\n",
    "tpFields.append(StructField('nconst', StringType(), True))\n",
    "tpFields.append(StructField('category', StringType(), True))\n",
    "tpFields.append(StructField('job', StringType(), True))\n",
    "tpFields.append(StructField('characters', StringType(), True))                     \n",
    "\n",
    "tpSchema = StructType(tpFields)\n",
    "\n",
    "#create df\n",
    "titlePrincipals_df = sqlContext.createDataFrame(titlePrincipals_rdd, tpSchema)\n",
    "\n",
    "#clean data\n",
    "titlePrincipals_df = titlePrincipals_df.filter(titlePrincipals_df.category.contains(\"actor\") | titlePrincipals_df.category.contains(\"actress\"))\n",
    "titlePrincipals_df = titlePrincipals_df.filter(titlePrincipals_df.characters !=\"\\\\N\")\n",
    "titlePrincipals_df = titlePrincipals_df.drop('job').sort('tconst', ascending=True)\n",
    "\n",
    "titlePrincipals_df.show(2, truncate = True)\n",
    "\n",
    "#rdd\n",
    "titlePrincipals_rdd = titlePrincipals_df.rdd.map(list)\n",
    "titlePrincipals_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------+\n",
      "|   tconst|averageRating|numVotes|\n",
      "+---------+-------------+--------+\n",
      "|tt0000001|          5.8|    1416|\n",
      "|tt0000002|          6.4|     167|\n",
      "+---------+-------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.RATINGS\n",
    "#tconst, averageRating, numVotes\n",
    "titleRatings_data = sc.textFile(filepath + '/IMDB/titleRatings.tsv')\n",
    "titleRatings_rdd = titleRatings_data.filter(lambda l: 'averageRating' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "trFields = []\n",
    "trFields.append(StructField('tconst', StringType(), True))\n",
    "trFields.append(StructField('averageRating', StringType(), True))\n",
    "trFields.append(StructField('numVotes', StringType(), True))                    \n",
    "\n",
    "trSchema = StructType(trFields)\n",
    "\n",
    "#create df\n",
    "titleRatings_df= sqlContext.createDataFrame(titleRatings_rdd, trSchema)\n",
    "\n",
    "titleRatings_df.show(2, truncate = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join title.Basics and title.Akas and title.Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------+---------+---------+-------+--------------------+-------------+--------+\n",
      "|  titleId|               title|region|titleType|startYear|endYear|              genres|averageRating|numVotes|\n",
      "+---------+--------------------+------+---------+---------+-------+--------------------+-------------+--------+\n",
      "|tt0021617|   Arizona Territory|    US|    movie|     1950|     \\N|             Western|          5.4|      18|\n",
      "|tt0031603|Made in Germany -...|    US|    movie|     1957|     \\N|     Biography,Drama|          6.5|      13|\n",
      "|tt0035423|    Kate and Leopold|    US|    movie|     2001|     \\N|Comedy,Fantasy,Ro...|          6.4|   72053|\n",
      "+---------+--------------------+------+---------+---------+-------+--------------------+-------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(titleId='tt0021617', title='Arizona Territory', region='US', titleType='movie', startYear='1950', endYear='\\\\N', genres='Western', averageRating='5.4', numVotes='18'),\n",
       " Row(titleId='tt0031603', title='Made in Germany - Die dramatische Geschichte des Hauses Zeiss', region='US', titleType='movie', startYear='1957', endYear='\\\\N', genres='Biography,Drama', averageRating='6.5', numVotes='13'),\n",
       " Row(titleId='tt0035423', title='Kate and Leopold', region='US', titleType='movie', startYear='2001', endYear='\\\\N', genres='Comedy,Fantasy,Romance', averageRating='6.4', numVotes='72053'),\n",
       " Row(titleId='tt0035933', title='Elephant Fury', region='US', titleType='movie', startYear='1953', endYear='\\\\N', genres='Drama,War', averageRating='4.2', numVotes='6'),\n",
       " Row(titleId='tt0036493', title='Black Devils of Kali', region='US', titleType='movie', startYear='1954', endYear='\\\\N', genres='Action,Adventure,Mystery', averageRating='5.1', numVotes='17'),\n",
       " Row(titleId='tt0040018', title=\"It's Forever Springtime\", region='US', titleType='movie', startYear='1950', endYear='\\\\N', genres='Comedy,Drama', averageRating='6.7', numVotes='62'),\n",
       " Row(titleId='tt0040284', title='The Last Days of Pompeii', region='US', titleType='movie', startYear='1950', endYear='\\\\N', genres='Drama,History', averageRating='5.8', numVotes='68'),\n",
       " Row(titleId='tt0040533', title='Faust and the Devil', region='US', titleType='movie', startYear='1950', endYear='\\\\N', genres='Drama,Musical', averageRating='6.7', numVotes='15'),\n",
       " Row(titleId='tt0040846', title='The Art of Burlesque', region='US', titleType='movie', startYear='1950', endYear='\\\\N', genres='Comedy', averageRating='7.4', numVotes='8'),\n",
       " Row(titleId='tt0041024', title='The Ford Television Theatre', region='US', titleType='tvSeries', startYear='1952', endYear='1957', genres='Comedy,Drama,Music', averageRating='8.3', numVotes='128')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aliases\n",
    "Basics = titleBasics_df.alias('Basics')\n",
    "Akas = titleAkas_df.alias('Akas')\n",
    "Ratings = titleRatings_df.alias('Ratings')\n",
    "\n",
    "#join title.Basics to title.Akas\n",
    "AkasBasics = Akas.join(Basics, Akas.titleId == Basics.tconst, how='left')\n",
    "\n",
    "#clean data 1st join\n",
    "AkasBasics = AkasBasics.filter(AkasBasics.isAdult =='0')\n",
    "AkasBasics = AkasBasics.drop('ordering', 'language', 'types', \n",
    "                               'attributes', 'isOriginalTitle', 'tconst', \n",
    "                               'primaryTitle', 'isAdult')\n",
    "AkasBasics = AkasBasics.filter(AkasBasics.titleType.contains(\"movie\"))\n",
    "AkasBasics = AkasBasics.filter(AkasBasics.startYear >='1950')\n",
    "\n",
    "#join AkasBasics with title.Ratings\n",
    "titleABR = AkasBasics.join(Ratings, AkasBasics.titleId == Ratings.tconst, how='left')\n",
    "\n",
    "#clean data 2nd join\n",
    "titleABR = titleABR.drop('tconst')\n",
    "\n",
    "titleABR.show(3, truncate = True)\n",
    "\n",
    "#rdd\n",
    "titleABR_rdd = titleABR.rdd.map(list).filter(lambda x: x[7] != None)\n",
    "titleABR_rdd.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BabyNames\n",
    "## RDD Creation\n",
    "### US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#US Baby Names\n",
    "#NationalNames.csv\n",
    "#Id,Name,Year,Gender,Count\n",
    "nationalname_rdd_init = (sc.textFile(filepath + '/us-baby-names/NationalNames.csv'))\n",
    "nationalname_rdd = nationalname_rdd_init.filter(lambda x: 'Gender' not in x)\n",
    "nationalname_rdd = nationalname_rdd.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State Baby Names\n",
    "#StateNames.csv\n",
    "#Id,Name,Year,Gender,State,Count\n",
    "full_statename_rdd_init = (sc.textFile(filepath + '/us-baby-names/StateNames.csv'))\n",
    "full_statename_rdd = full_statename_rdd_init.filter(lambda x: 'Gender' not in x).map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n",
    "us_states_abbreviations = list(us_states.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "## How many times does name x occur per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arwen\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~silkeh/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"Arwen\"\n",
    "\n",
    "def name_per_year_plot(name):\n",
    "    print(name)\n",
    "    pername_nationalname_rdd = nationalname_rdd.filter(lambda x: x[1] == str(name))\n",
    "    # Create a trace\n",
    "\n",
    "    trace = go.Scatter(\n",
    "        x = pername_nationalname_rdd.map(lambda x: int(x[2])).collect(),\n",
    "        y = pername_nationalname_rdd.map(lambda x: int(x[4])).collect()\n",
    "    )\n",
    "\n",
    "    data = [trace]\n",
    "\n",
    "    return(py.iplot(data, filename='basic-line'))\n",
    "\n",
    "name_per_year_plot(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 movies for year x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['tt0626054',\n",
       "  'Episode #1.11',\n",
       "  'US',\n",
       "  'tvEpisode',\n",
       "  '2001',\n",
       "  '\\\\N',\n",
       "  'Comedy',\n",
       "  '1.0',\n",
       "  '7'],\n",
       " ['tt0626430',\n",
       "  'Episode dated 14 March 2001',\n",
       "  'US',\n",
       "  'tvEpisode',\n",
       "  '2001',\n",
       "  '\\\\N',\n",
       "  'Comedy,Talk-Show',\n",
       "  '1.1',\n",
       "  '17'],\n",
       " ['tt0314134',\n",
       "  'Gulczas, what do you think...',\n",
       "  'US',\n",
       "  'movie',\n",
       "  '2001',\n",
       "  '\\\\N',\n",
       "  'Comedy,Crime',\n",
       "  '1.3',\n",
       "  '1076'],\n",
       " ['tt2402465',\n",
       "  'Joni Table Talk',\n",
       "  'US',\n",
       "  'tvSeries',\n",
       "  '2001',\n",
       "  '\\\\N',\n",
       "  'Talk-Show',\n",
       "  '1.3',\n",
       "  '10'],\n",
       " ['tt0285357',\n",
       "  'Elimidate Deluxe',\n",
       "  'US',\n",
       "  'tvSeries',\n",
       "  '2001',\n",
       "  '\\\\N',\n",
       "  '\\\\N',\n",
       "  '1.4',\n",
       "  '9'],\n",
       " ['tt0626459',\n",
       "  'Episode dated 9 July 2001',\n",
       "  'US',\n",
       "  'tvEpisode',\n",
       "  '2001',\n",
       "  '\\\\N',\n",
       "  'Comedy,Talk-Show',\n",
       "  '1.5',\n",
       "  '58'],\n",
       " ['tt0367362',\n",
       "  'Love Bytes',\n",
       "  'US',\n",
       "  'tvSeries',\n",
       "  '2001',\n",
       "  '\\\\N',\n",
       "  'Comedy',\n",
       "  '1.6',\n",
       "  '20'],\n",
       " ['tt0689975',\n",
       "  'Episode dated 13 February 2001',\n",
       "  'US',\n",
       "  'tvEpisode',\n",
       "  '2001',\n",
       "  '\\\\N',\n",
       "  'Comedy,Talk-Show',\n",
       "  '1.6',\n",
       "  '7'],\n",
       " ['tt0690108',\n",
       "  'Episode dated 4 December 2001',\n",
       "  'US',\n",
       "  'tvEpisode',\n",
       "  '2001',\n",
       "  '\\\\N',\n",
       "  'Comedy,Talk-Show',\n",
       "  '1.6',\n",
       "  '7'],\n",
       " ['tt0728434',\n",
       "  'Episode #9.183',\n",
       "  'US',\n",
       "  'tvEpisode',\n",
       "  '2001',\n",
       "  '\\\\N',\n",
       "  'Comedy,Music,Talk-Show',\n",
       "  '1.6',\n",
       "  '9']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titleABR_rdd.filter(lambda x: x[4] == '2001').sortBy(lambda x: float(x[7]), reverse = True).take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
