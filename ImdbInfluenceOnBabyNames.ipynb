{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "import folium\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.widgets import GraphWidget\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='silkeh', api_key='GwBAmaelgKfgkrmuL691')\n",
    "\n",
    "separator = '\\t'\n",
    "#Eva\n",
    "filepath = 'D:/Workspace/_DataMining/DataSets'\n",
    "#Silke\n",
    "#filepath = 'C:/Users/Silke/Documents/GitHub/DataMiningAP'\n",
    "\n",
    "#output filepath for new csv files\n",
    "#Eva\n",
    "#outputFilepath = 'D:/Workspace/_DataMining/DataSets/IMDB_new'\n",
    "#Silke\n",
    "#outputFilepath = 'C:/Users/Silke/Documents/GitHub/DataMiningAP/IMDB_new'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB\n",
    "## Creation of RDD's and DF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+-------+---------+-------+--------------------+\n",
      "|   tconst|titleType|        primaryTitle|isAdult|startYear|endYear|              genres|\n",
      "+---------+---------+--------------------+-------+---------+-------+--------------------+\n",
      "|tt0000001|    short|          Carmencita|      0|     1894|     \\N|   Documentary,Short|\n",
      "|tt0000002|    short|Le clown et ses c...|      0|     1892|     \\N|     Animation,Short|\n",
      "|tt0000003|    short|      Pauvre Pierrot|      0|     1892|     \\N|Animation,Comedy,...|\n",
      "|tt0000004|    short|         Un bon bock|      0|     1892|     \\N|     Animation,Short|\n",
      "|tt0000005|    short|    Blacksmith Scene|      0|     1893|     \\N|        Comedy,Short|\n",
      "+---------+---------+--------------------+-------+---------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.BASICS\n",
    "#tconst, titleType, primaryTitle, originalTitle, isAdult, startYear, endYear, runtimeMinutes, genres\n",
    "titleBasics_data = sc.textFile(filepath + '/IMDB/titleBasics.tsv')\n",
    "titleBasics_rdd = titleBasics_data.filter(lambda l: 'primaryTitle' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "tbFields = []\n",
    "tbFields.append(StructField('tconst', StringType(), True))\n",
    "tbFields.append(StructField('titleType', StringType(), True))\n",
    "tbFields.append(StructField('primaryTitle', StringType(), True))\n",
    "tbFields.append(StructField('originalTitle', StringType(), True))\n",
    "tbFields.append(StructField('isAdult', StringType(), True))\n",
    "tbFields.append(StructField('startYear', StringType(), True))\n",
    "tbFields.append(StructField('endYear', StringType(), True))\n",
    "tbFields.append(StructField('runtimeMinutes', StringType(), True))\n",
    "tbFields.append(StructField('genres', StringType(), True))                           \n",
    "\n",
    "tbSchema = StructType(tbFields)\n",
    "\n",
    "#create df\n",
    "titleBasics_df = sqlContext.createDataFrame(titleBasics_rdd, tbSchema)\n",
    "\n",
    "#clean data\n",
    "titleBasics_df = titleBasics_df.drop('originalTitle', 'runtimeMinutes').sort('tconst', ascending=True)\n",
    "titleBasics_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+--------+-----------+--------------------+---------------+\n",
      "|  titleId|ordering|               title|region|language|      types|          attributes|isOriginalTitle|\n",
      "+---------+--------+--------------------+------+--------+-----------+--------------------+---------------+\n",
      "|tt0000001|       3|          Carmencita|    US|      \\N|         \\N|                  \\N|              0|\n",
      "|tt0000002|       5|The Clown and His...|    US|      \\N|         \\N|literal English t...|              0|\n",
      "|tt0000005|       1| Blacksmithing Scene|    US|      \\N|alternative|                  \\N|              0|\n",
      "|tt0000006|       3|   Chinese Opium Den|    US|      \\N|         \\N|                  \\N|              0|\n",
      "|tt0000007|       1|Corbett and Court...|    US|      \\N|         \\N|                  \\N|              0|\n",
      "+---------+--------+--------------------+------+--------+-----------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.AKAS\n",
    "#tconst, ordering, title, region, language, types, attributes, isOriginalTitle\n",
    "titleAkas_data = sc.textFile(filepath + '/IMDB/titleAkas.tsv')\n",
    "titleAkas_rdd = titleAkas_data.filter(lambda l: 'ordering' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "taFields = []\n",
    "taFields.append(StructField('titleId', StringType(), True))\n",
    "taFields.append(StructField('ordering', StringType(), True))\n",
    "taFields.append(StructField('title', StringType(), True))\n",
    "taFields.append(StructField('region', StringType(), True))\n",
    "taFields.append(StructField('language', StringType(), True))\n",
    "taFields.append(StructField('types', StringType(), True))\n",
    "taFields.append(StructField('attributes', StringType(), True))\n",
    "taFields.append(StructField('isOriginalTitle', StringType(), True))                       \n",
    "\n",
    "taSchema = StructType(taFields)\n",
    "\n",
    "#create df\n",
    "titleAkas_df= sqlContext.createDataFrame(titleAkas_rdd, taSchema)\n",
    "\n",
    "#clean data\n",
    "titleAkas_df = titleAkas_df.filter(titleAkas_df.region =='US')\n",
    "titleAkas_df = titleAkas_df.dropDuplicates(['titleId']).sort('titleId', ascending=True)\n",
    "\n",
    "titleAkas_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+--------+--------------+\n",
      "|   tconst|ordering|   nconst|category|    characters|\n",
      "+---------+--------+---------+--------+--------------+\n",
      "|tt0000005|       2|nm0653042|   actor| [\"Assistant\"]|\n",
      "|tt0000005|       1|nm0443482|   actor|[\"Blacksmith\"]|\n",
      "+---------+--------+---------+--------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.PRINCIPALS\n",
    "#tconst, ordering, nconst, category, job, characters\n",
    "titlePrincipals_data = sc.textFile(filepath + '/IMDB/titlePrincipals.tsv')\n",
    "titlePrincipals_rdd = titlePrincipals_data.filter(lambda l: 'ordering' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "tpFields = []\n",
    "tpFields.append(StructField('tconst', StringType(), True))\n",
    "tpFields.append(StructField('ordering', StringType(), True))\n",
    "tpFields.append(StructField('nconst', StringType(), True))\n",
    "tpFields.append(StructField('category', StringType(), True))\n",
    "tpFields.append(StructField('job', StringType(), True))\n",
    "tpFields.append(StructField('characters', StringType(), True))                     \n",
    "\n",
    "tpSchema = StructType(tpFields)\n",
    "\n",
    "#create df\n",
    "titlePrincipals_df = sqlContext.createDataFrame(titlePrincipals_rdd, tpSchema)\n",
    "\n",
    "#clean data\n",
    "titlePrincipals_df = titlePrincipals_df.filter(titlePrincipals_df.category.contains(\"actor\") | titlePrincipals_df.category.contains(\"actress\"))\n",
    "titlePrincipals_df = titlePrincipals_df.filter(titlePrincipals_df.characters !=\"\\\\N\")\n",
    "titlePrincipals_df = titlePrincipals_df.drop('job').sort('tconst', ascending=True)\n",
    "\n",
    "titlePrincipals_df.show(2, truncate = True)\n",
    "\n",
    "#write to csv file\n",
    "titlePrincipals_df.repartition(1).write.option(\"sep\", \"|\").format('com.databricks.spark.csv').save(outputFilepath + \"/titlePrincipals_df.csv\",header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------+\n",
      "|   tconst|averageRating|numVotes|\n",
      "+---------+-------------+--------+\n",
      "|tt0000001|          5.8|    1416|\n",
      "|tt0000002|          6.4|     167|\n",
      "+---------+-------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.RATINGS\n",
    "#tconst, averageRating, numVotes\n",
    "titleRatings_data = sc.textFile(filepath + '/IMDB/titleRatings.tsv')\n",
    "titleRatings_rdd = titleRatings_data.filter(lambda l: 'averageRating' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "trFields = []\n",
    "trFields.append(StructField('tconst', StringType(), True))\n",
    "trFields.append(StructField('averageRating', StringType(), True))\n",
    "trFields.append(StructField('numVotes', StringType(), True))                    \n",
    "\n",
    "trSchema = StructType(trFields)\n",
    "\n",
    "#create df\n",
    "titleRatings_df= sqlContext.createDataFrame(titleRatings_rdd, trSchema)\n",
    "\n",
    "titleRatings_df.show(2, truncate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join title.Basics and title.Akas and title.Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+------+---------+---------+-------+--------------------+-------------+--------+\n",
      "|  titleId|            title|region|titleType|startYear|endYear|              genres|averageRating|numVotes|\n",
      "+---------+-----------------+------+---------+---------+-------+--------------------+-------------+--------+\n",
      "|tt0042899|   Ghost Mountain|    US|    movie|     1950|     \\N|Action,Adventure,...|          6.8|     791|\n",
      "|tt0042917|Salt Lake Raiders|    US|    movie|     1950|     \\N|             Western|          6.5|      59|\n",
      "|tt0043729|  Lawless Cowboys|    US|    movie|     1951|     \\N|             Western|          6.1|       9|\n",
      "+---------+-----------------+------+---------+---------+-------+--------------------+-------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Aliases\n",
    "Basics = titleBasics_df.alias('Basics')\n",
    "Akas = titleAkas_df.alias('Akas')\n",
    "Ratings = titleRatings_df.alias('Ratings')\n",
    "\n",
    "#join title.Basics to title.Akas\n",
    "AkasBasics = Akas.join(Basics, Akas.titleId == Basics.tconst, how='left')\n",
    "\n",
    "#clean data 1st join\n",
    "AkasBasics = AkasBasics.filter(AkasBasics.isAdult =='0')\n",
    "AkasBasics = AkasBasics.drop('ordering', 'language', 'types', \n",
    "                               'attributes', 'isOriginalTitle', 'tconst', \n",
    "                               'primaryTitle', 'isAdult')\n",
    "AkasBasics = AkasBasics.filter(AkasBasics.titleType.contains(\"movie\"))\n",
    "AkasBasics = AkasBasics.filter(AkasBasics.startYear >='1950')\n",
    "\n",
    "#join AkasBasics with title.Ratings\n",
    "titleABR = AkasBasics.join(Ratings, AkasBasics.titleId == Ratings.tconst, how='left')\n",
    "\n",
    "#clean data 2nd join\n",
    "titleABR = titleABR.drop('tconst')\n",
    "\n",
    "titleABR.show(3, truncate = True)\n",
    "\n",
    "#write to csv file\n",
    "titleABR.repartition(1).write.option(\"sep\", \"|\").format('com.databricks.spark.csv').save(outputFilepath + \"/titleABR.csv\", header = 'true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BabyNames\n",
    "## RDD Creation\n",
    "### US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#US Baby Names\n",
    "#NationalNames.csv\n",
    "#Id,Name,Year,Gender,Count\n",
    "nationalname_rdd_init = (sc.textFile(filepath + '/us-baby-names/NationalNames.csv'))\n",
    "nationalname_rdd = nationalname_rdd_init.filter(lambda x: 'Gender' not in x)\n",
    "nationalname_rdd = nationalname_rdd.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State Baby Names\n",
    "#StateNames.csv\n",
    "#Id,Name,Year,Gender,State,Count\n",
    "full_statename_rdd_init = (sc.textFile(filepath + '/us-baby-names/StateNames.csv'))\n",
    "full_statename_rdd = full_statename_rdd_init.filter(lambda x: 'Gender' not in x).map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n",
    "us_states_abbreviations = list(us_states.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 movies for year x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tt0167260', 'The Lord of the Rings: The Return of the King', 'US', 'movie', '2003', '\\\\N', 'Action,Adventure,Drama', '8.9', '1424076'], ['tt0332569', 'As a Bad Dream', 'US', 'movie', '2003', '\\\\N', 'Drama', '8.5', '225'], ['tt0346336', 'The Best of Youth', 'US', 'movie', '2003', '\\\\N', 'Drama,Romance', '8.5', '18505'], ['tt0339535', 'The Professional', 'US', 'movie', '2003', '\\\\N', 'Comedy,Drama', '8.4', '5163'], ['tt0347779', 'Pinjar', 'US', 'movie', '2003', '\\\\N', 'Drama', '8.1', '2262'], ['tt0353969', 'Memories of Murder', 'US', 'movie', '2003', '\\\\N', 'Action,Crime,Drama', '8.1', '93468'], ['tt0374546', 'Spring, Summer, Fall, Winter... and Spring', 'US', 'movie', '2003', '\\\\N', 'Drama,Romance', '8.1', '69526'], ['tt0266697', 'Kill Bill Part 1', 'US', 'movie', '2003', '\\\\N', 'Action,Crime,Thriller', '8.1', '865430'], ['tt0266543', 'Finding Nemo', 'US', 'movie', '2003', '\\\\N', 'Adventure,Animation,Comedy', '8.1', '829239'], ['tt0347304', 'Tomorrow May Never Come', 'US', 'movie', '2003', '\\\\N', 'Comedy,Drama,Romance', '8.0', '55203']]\n",
      "['tt0167260', 'tt0332569', 'tt0346336', 'tt0339535', 'tt0347779', 'tt0353969', 'tt0374546', 'tt0266697', 'tt0266543', 'tt0347304']\n"
     ]
    }
   ],
   "source": [
    "separator = '|'\n",
    "year = '2003'\n",
    "\n",
    "#create rdd\n",
    "titleABR_data = sc.textFile(filepath + '/IMDB_new/titleABR.csv/titleABR.csv')\n",
    "titleABR_rdd = titleABR_data.filter(lambda l: 'region' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#get top 10 movies by year\n",
    "top_movies_rdd = titleABR_rdd.filter(lambda x: x[4] == year).filter(lambda x: x[7] != '').filter(lambda x: ('Documentary') not in x[6]).filter(lambda x: float(x[8]) >99).sortBy(lambda x: float(x[7]), False)\n",
    "print(top_movies_rdd.take(10))\n",
    "top_movies_list = top_movies_rdd.map(lambda x: x[0]).take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get principal characters for top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter\n",
      "Hermione Granger\n",
      "Ron Weasley\n",
      "Professor Albus Dumbledore\n",
      "Tommy Conlon\n",
      "Paddy Conlon\n",
      "Brendan Conlon\n",
      "Tess Conlon\n",
      "Skeeter Phelan\n",
      "Aibileen Clark\n",
      "Minny Jackson\n",
      "Hilly Holbrook\n",
      "Arjun Saluja\n",
      "Imraan Qureshi\n",
      "Kabir Dewan\n",
      "Laila\n",
      "Philippe\n",
      "Driss\n",
      "Yvonne\n",
      "Magalie\n",
      "Gustav,Constable\n",
      "The Creature,Victor Frankenstein\n",
      "The Creature,Victor Frankenstein\n",
      "Female Creature\n",
      "Gretel,Clarice\n",
      "Nader\n",
      "Simin\n",
      "Razieh\n",
      "Hojjat\n",
      "Carl\n",
      "Brenda\n",
      "Phantom,Hans,Bob\n",
      "Gatekeeper\n",
      "Earl McGraw\n",
      "Buck\n",
      "Bill\n",
      "Hattori Hanzo\n",
      "Sofie Fatale\n",
      "Vernita Green\n",
      "Gogo Yubari\n",
      "Budd\n",
      "Harry S. Plinkett\n"
     ]
    }
   ],
   "source": [
    "#create rdd\n",
    "titlePrincipals_data = sc.textFile(filepath + '/IMDB_new/titlePrincipals_df.csv/titlePrincipals.csv')\n",
    "titlePrincipals_rdd = titlePrincipals_data.filter(lambda l: 'category' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#filter out characters by id's in top 10 list\n",
    "top_characters_rdd = titlePrincipals_rdd.filter(lambda x: x[0] in top_movies_list)                                             \n",
    "top_characters_list = top_characters_rdd.map(lambda x: x[4]).collect()\n",
    "for x in top_characters_list:\n",
    "    print(x.replace('\\\"', '').replace('[', '').replace(']', '').replace('\\\\', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity of x name by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trinity\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~silkeh/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#name variable used for further analysis\n",
    "name = \"Trinity\"\n",
    "\n",
    "#isolating year variable with highest frequency\n",
    "sortByCount = nationalname_rdd.filter(lambda x: x[1] == str(name)).sortBy(lambda x: int(x[4]), False)\n",
    "year = sortByCount.first()\n",
    "year = year[2]\n",
    "\n",
    "#method definition for graph\n",
    "def name_per_year_plot(name):\n",
    "    print(name)\n",
    "    pername_nationalname_rdd = nationalname_rdd.filter(lambda x: x[1] == str(name))\n",
    "    # Create a trace\n",
    "\n",
    "    trace = go.Scatter(\n",
    "        x = pername_nationalname_rdd.map(lambda x: int(x[2])).collect(),\n",
    "        y = pername_nationalname_rdd.map(lambda x: int(x[4])).collect()\n",
    "    )\n",
    "\n",
    "    data = [trace]\n",
    "    \n",
    "    return(py.iplot(data, filename='basic-line'))\n",
    "\n",
    "#create graph for given name\n",
    "name_per_year_plot(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap of popularity by state for most popular year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AK  22\n",
      "AL  124\n",
      "AR  82\n",
      "AZ  160\n",
      "CA  489\n",
      "CO  99\n",
      "CT  50\n",
      "DC  11\n",
      "DE  12\n",
      "FL  350\n",
      "GA  233\n",
      "HI  34\n",
      "IA  48\n",
      "ID  35\n",
      "IL  192\n",
      "IN  154\n",
      "KS  71\n",
      "KY  80\n",
      "KY  31\n",
      "LA  139\n",
      "LA  5\n",
      "MA  67\n",
      "MD  108\n",
      "ME  29\n",
      "MI  153\n",
      "MN  58\n",
      "MO  138\n",
      "MS  74\n",
      "MT  16\n",
      "NC  202\n",
      "ND  7\n",
      "NE  31\n",
      "NH  15\n",
      "NJ  80\n",
      "NM  49\n",
      "NV  57\n",
      "NY  204\n",
      "OH  241\n",
      "OK  130\n",
      "OR  67\n",
      "PA  181\n",
      "RI  10\n",
      "SC  107\n",
      "SD  17\n",
      "TN  147\n",
      "TX  569\n",
      "TX  7\n",
      "UT  51\n",
      "VA  162\n",
      "VT  5\n",
      "WA  104\n",
      "WI  116\n",
      "WV  40\n",
      "WY  10\n"
     ]
    }
   ],
   "source": [
    "#NOTE: dataset US Baby Names contains only name instances where count/year >= 5\n",
    "#connecting highest frequency year to popularity per state\n",
    "name_frequency_state = full_statename_rdd.filter(lambda x: x[2] == year).filter(lambda x: x[1] == name)\n",
    "states = name_frequency_state.map(lambda x: x[4]).collect()\n",
    "amount_state = name_frequency_state.map(lambda x: x[5]).collect()\n",
    "\n",
    "for x in range(0, len(states)):\n",
    "    print(states[x] + '  ' + amount_state[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~silkeh/52.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#us_states_abbreviations\n",
    "#full_statename_rdd\n",
    "\n",
    "trc = dict (\n",
    "    type = 'choropleth',\n",
    "    locations = states,\n",
    "    locationmode = 'USA-states',\n",
    "    colorscale ='YlOrRd',\n",
    "    z = amount_state, \n",
    "    reversescale = True)\n",
    "lyt = dict ( geo = dict (scope ='usa'))\n",
    "map = go.Figure (data = [trc],\n",
    "    layout = lyt)\n",
    "py.iplot(map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 20 baby names for year x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emily\t\t25685\n",
      "Emma\t\t22701\n",
      "Madison\t\t20197\n",
      "Hannah\t\t17628\n",
      "Olivia\t\t16142\n",
      "Abigail\t\t15918\n",
      "Alexis\t\t14857\n",
      "Ashley\t\t14512\n",
      "Elizabeth\t\t14094\n",
      "Samantha\t\t13862\n",
      "Isabella\t\t13770\n",
      "Sarah\t\t13753\n",
      "Grace\t\t12770\n",
      "Alyssa\t\t12743\n",
      "Lauren\t\t11046\n",
      "Kayla\t\t10949\n",
      "Brianna\t\t10580\n",
      "Jessica\t\t10445\n",
      "Taylor\t\t10304\n",
      "Sophia\t\t9682\n"
     ]
    }
   ],
   "source": [
    "#US Baby Names\n",
    "#NationalNames.csv\n",
    "#Id,Name,Year,Gender,Count\n",
    "\n",
    "#F = female, M = male\n",
    "gender = 'F'\n",
    "\n",
    "#get sorted list of names by year\n",
    "top_names_list = nationalname_rdd.filter(lambda x : x[2] == year).filter(lambda x: x[3] == gender).sortBy(lambda x: int(x[4]), False)\n",
    "\n",
    "#show top 20\n",
    "names = top_names_list.map(lambda x: x[1]).collect()\n",
    "amount_name = top_names_list.map(lambda x: x[4]).collect()\n",
    "\n",
    "for x in range(0, 20):\n",
    "    print(names[x] + '\\t\\t' + amount_name[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
