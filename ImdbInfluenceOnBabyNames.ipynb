{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.genUID = function() {\n",
       "    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {\n",
       "        var r = Math.random()*16|0, v = c == 'x' ? r : (r&0x3|0x8);\n",
       "        return v.toString(16);\n",
       "    });\n",
       "};\n",
       "\n",
       "\n",
       "define('graphWidget', [\"@jupyter-widgets/base\"], function (widget) {\n",
       "\n",
       "    var GraphView = widget.DOMWidgetView.extend({\n",
       "        render: function(){\n",
       "            var that = this;\n",
       "\n",
       "            var graphId = window.genUID();\n",
       "            var loadingId = 'loading-'+graphId;\n",
       "\n",
       "\n",
       "            var _graph_url = that.model.get('_graph_url');\n",
       "\n",
       "            // variable plotlyDomain in the case of enterprise\n",
       "            var url_parts = _graph_url.split('/');\n",
       "            var plotlyDomain = url_parts[0] + '//' + url_parts[2];\n",
       "\n",
       "            if(!('plotlyDomains' in window)){\n",
       "                window.plotlyDomains = {};\n",
       "            }\n",
       "            window.plotlyDomains[graphId] = plotlyDomain;\n",
       "\n",
       "            // Place IFrame in output cell div `$el`\n",
       "            that.$el.css('width', '100%');\n",
       "            that.$graph = $(['<iframe id=\"'+graphId+'\"',\n",
       "                             'src=\"'+_graph_url+'.embed\"',\n",
       "                             'seamless',\n",
       "                             'style=\"border: none;\"',\n",
       "                             'width=\"100%\"',\n",
       "                             'height=\"600\">',\n",
       "                             '</iframe>'].join(' '));\n",
       "            that.$graph.appendTo(that.$el);\n",
       "\n",
       "            that.$loading = $('<div id=\"'+loadingId+'\">Initializing...</div>')\n",
       "                            .appendTo(that.$el);\n",
       "\n",
       "            // for some reason the 'width' is being changed in IPython 3.0.0\n",
       "            // for the containing `div` element. There's a flicker here, but\n",
       "            // I was unable to fix it otherwise.\n",
       "            setTimeout(function ()  {\n",
       "                if (IPYTHON_VERSION === '3') {\n",
       "                    $('#' + graphId)[0].parentElement.style.width = '100%';\n",
       "                }\n",
       "            }, 500);\n",
       "\n",
       "            // initialize communication with the iframe\n",
       "            if(!('pingers' in window)){\n",
       "                window.pingers = {};\n",
       "            }\n",
       "\n",
       "            window.pingers[graphId] = setInterval(function() {\n",
       "                that.graphContentWindow = $('#'+graphId)[0].contentWindow;\n",
       "                that.graphContentWindow.postMessage({task: 'ping'}, plotlyDomain);\n",
       "            }, 200);\n",
       "\n",
       "            // Assign a message listener to the 'message' events\n",
       "            // from iframe's postMessage protocol.\n",
       "            // Filter the messages by iframe src so that the right message\n",
       "            // gets passed to the right widget\n",
       "            if(!('messageListeners' in window)){\n",
       "                 window.messageListeners = {};\n",
       "            }\n",
       "\n",
       "            window.messageListeners[graphId] = function(e) {\n",
       "                if(_graph_url.indexOf(e.origin)>-1) {\n",
       "                    var frame = document.getElementById(graphId);\n",
       "\n",
       "                    if(frame === null){\n",
       "                        // frame doesn't exist in the dom anymore, clean up it's old event listener\n",
       "                        window.removeEventListener('message', window.messageListeners[graphId]);\n",
       "                        clearInterval(window.pingers[graphId]);\n",
       "                    } else if(frame.contentWindow === e.source) {\n",
       "                        // TODO: Stop event propagation, so each frame doesn't listen and filter\n",
       "                        var frameContentWindow = $('#'+graphId)[0].contentWindow;\n",
       "                        var message = e.data;\n",
       "\n",
       "                        if('pong' in message && message.pong) {\n",
       "                            $('#loading-'+graphId).hide();\n",
       "                            clearInterval(window.pingers[graphId]);\n",
       "                            that.send({event: 'pong', graphId: graphId});\n",
       "                        } else if (message.type==='hover' ||\n",
       "                                   message.type==='zoom'  ||\n",
       "                                   message.type==='click' ||\n",
       "                                   message.type==='unhover') {\n",
       "\n",
       "                            // click and hover events contain all of the data in the traces,\n",
       "                            // which can be a very large object and may take a ton of time\n",
       "                            // to pass to the python backend. Strip out the data, and require\n",
       "                            // the user to call get_figure if they need trace information\n",
       "                            if(message.type !== 'zoom') {\n",
       "                                for(var i in message.points) {\n",
       "                                    delete message.points[i].data;\n",
       "                                    delete message.points[i].fullData;\n",
       "                                }\n",
       "                            }\n",
       "                            that.send({event: message.type, message: message, graphId: graphId});\n",
       "                        } else if (message.task === 'getAttributes') {\n",
       "                            that.send({event: 'getAttributes', response: message.response});\n",
       "                        }\n",
       "                    }\n",
       "                }\n",
       "            };\n",
       "\n",
       "            window.removeEventListener('message', window.messageListeners[graphId]);\n",
       "            window.addEventListener('message', window.messageListeners[graphId]);\n",
       "\n",
       "        },\n",
       "\n",
       "        update: function() {\n",
       "            // Listen for messages from the graph widget in python\n",
       "            var jmessage = this.model.get('_message');\n",
       "            var message = JSON.parse(jmessage);\n",
       "\n",
       "            // check for duplicate messages\n",
       "            if(!('messageIds' in window)){\n",
       "                window.messageIds = {};\n",
       "            }\n",
       "\n",
       "            if(!(message.uid in window.messageIds)){\n",
       "                // message hasn't been received yet, do stuff\n",
       "                window.messageIds[message.uid] = true;\n",
       "\n",
       "                if (message.fadeTo) {\n",
       "                    this.fadeTo(message);\n",
       "                } else {\n",
       "                    var plot = $('#' + message.graphId)[0].contentWindow;\n",
       "                    plot.postMessage(message, window.plotlyDomains[message.graphId]);\n",
       "                }\n",
       "            }\n",
       "\n",
       "            return GraphView.__super__.update.apply(this);\n",
       "        },\n",
       "\n",
       "        /**\n",
       "         * Wrapper for jquery's `fadeTo` function.\n",
       "         *\n",
       "         * @param message Contains the id we need to find the element.\n",
       "         */\n",
       "        fadeTo: function (message) {\n",
       "            var plot = $('#' + message.graphId);\n",
       "            plot.fadeTo(message.duration, message.opacity);\n",
       "        }\n",
       "    });\n",
       "\n",
       "    // Register the GraphView with the widget manager.\n",
       "    return {\n",
       "        GraphView: GraphView\n",
       "    }\n",
       "\n",
       "});\n",
       "\n",
       "//@ sourceURL=graphWidget.js\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "import folium\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, clear_output\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.widgets import GraphWidget\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='silkeh', api_key='GwBAmaelgKfgkrmuL691')\n",
    "\n",
    "separator = '\\t'\n",
    "#Eva\n",
    "#filepath = 'D:/Workspace/_DataMining/DataSets'\n",
    "#Silke\n",
    "filepath = 'C:/Users/Silke/Documents/GitHub/DataMiningAP'\n",
    "\n",
    "#output filepath for new csv files\n",
    "#Eva\n",
    "#outputFilepath = 'D:/Workspace/_DataMining/DataSets/IMDB_new'\n",
    "#Silke\n",
    "outputFilepath = 'C:/Users/Silke/Documents/GitHub/DataMiningAP/IMDB_new'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB\n",
    "## Creation of RDD's and DF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+-------+---------+-------+--------------------+\n",
      "|   tconst|titleType|        primaryTitle|isAdult|startYear|endYear|              genres|\n",
      "+---------+---------+--------------------+-------+---------+-------+--------------------+\n",
      "|tt0000001|    short|          Carmencita|      0|     1894|     \\N|   Documentary,Short|\n",
      "|tt0000002|    short|Le clown et ses c...|      0|     1892|     \\N|     Animation,Short|\n",
      "|tt0000003|    short|      Pauvre Pierrot|      0|     1892|     \\N|Animation,Comedy,...|\n",
      "|tt0000004|    short|         Un bon bock|      0|     1892|     \\N|     Animation,Short|\n",
      "|tt0000005|    short|    Blacksmith Scene|      0|     1893|     \\N|        Comedy,Short|\n",
      "+---------+---------+--------------------+-------+---------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.BASICS\n",
    "#tconst, titleType, primaryTitle, originalTitle, isAdult, startYear, endYear, runtimeMinutes, genres\n",
    "titleBasics_data = sc.textFile(filepath + '/IMDB/titleBasics.tsv')\n",
    "titleBasics_rdd = titleBasics_data.filter(lambda l: 'primaryTitle' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "tbFields = []\n",
    "tbFields.append(StructField('tconst', StringType(), True))\n",
    "tbFields.append(StructField('titleType', StringType(), True))\n",
    "tbFields.append(StructField('primaryTitle', StringType(), True))\n",
    "tbFields.append(StructField('originalTitle', StringType(), True))\n",
    "tbFields.append(StructField('isAdult', StringType(), True))\n",
    "tbFields.append(StructField('startYear', StringType(), True))\n",
    "tbFields.append(StructField('endYear', StringType(), True))\n",
    "tbFields.append(StructField('runtimeMinutes', StringType(), True))\n",
    "tbFields.append(StructField('genres', StringType(), True))                           \n",
    "\n",
    "tbSchema = StructType(tbFields)\n",
    "\n",
    "#create df\n",
    "titleBasics_df = sqlContext.createDataFrame(titleBasics_rdd, tbSchema)\n",
    "\n",
    "#clean data\n",
    "titleBasics_df = titleBasics_df.drop('originalTitle', 'runtimeMinutes').sort('tconst', ascending=True)\n",
    "titleBasics_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------------------+------+--------+-----------+--------------------+---------------+\n",
      "|  titleId|ordering|               title|region|language|      types|          attributes|isOriginalTitle|\n",
      "+---------+--------+--------------------+------+--------+-----------+--------------------+---------------+\n",
      "|tt0000001|       3|          Carmencita|    US|      \\N|         \\N|                  \\N|              0|\n",
      "|tt0000002|       5|The Clown and His...|    US|      \\N|         \\N|literal English t...|              0|\n",
      "|tt0000005|       1| Blacksmithing Scene|    US|      \\N|alternative|                  \\N|              0|\n",
      "|tt0000006|       3|   Chinese Opium Den|    US|      \\N|         \\N|                  \\N|              0|\n",
      "|tt0000007|       1|Corbett and Court...|    US|      \\N|         \\N|                  \\N|              0|\n",
      "+---------+--------+--------------------+------+--------+-----------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.AKAS\n",
    "#tconst, ordering, title, region, language, types, attributes, isOriginalTitle\n",
    "titleAkas_data = sc.textFile(filepath + '/IMDB/titleAkas.tsv')\n",
    "titleAkas_rdd = titleAkas_data.filter(lambda l: 'ordering' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "taFields = []\n",
    "taFields.append(StructField('titleId', StringType(), True))\n",
    "taFields.append(StructField('ordering', StringType(), True))\n",
    "taFields.append(StructField('title', StringType(), True))\n",
    "taFields.append(StructField('region', StringType(), True))\n",
    "taFields.append(StructField('language', StringType(), True))\n",
    "taFields.append(StructField('types', StringType(), True))\n",
    "taFields.append(StructField('attributes', StringType(), True))\n",
    "taFields.append(StructField('isOriginalTitle', StringType(), True))                       \n",
    "\n",
    "taSchema = StructType(taFields)\n",
    "\n",
    "#create df\n",
    "titleAkas_df= sqlContext.createDataFrame(titleAkas_rdd, taSchema)\n",
    "\n",
    "#clean data\n",
    "titleAkas_df = titleAkas_df.filter(titleAkas_df.region =='US')\n",
    "titleAkas_df = titleAkas_df.dropDuplicates(['titleId']).sort('titleId', ascending=True)\n",
    "\n",
    "titleAkas_df.show(5, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+--------+--------------+\n",
      "|   tconst|ordering|   nconst|category|    characters|\n",
      "+---------+--------+---------+--------+--------------+\n",
      "|tt0000005|       2|nm0653042|   actor| [\"Assistant\"]|\n",
      "|tt0000005|       1|nm0443482|   actor|[\"Blacksmith\"]|\n",
      "+---------+--------+---------+--------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.PRINCIPALS\n",
    "#tconst, ordering, nconst, category, job, characters\n",
    "titlePrincipals_data = sc.textFile(filepath + '/IMDB/titlePrincipals.tsv')\n",
    "titlePrincipals_rdd = titlePrincipals_data.filter(lambda l: 'ordering' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "tpFields = []\n",
    "tpFields.append(StructField('tconst', StringType(), True))\n",
    "tpFields.append(StructField('ordering', StringType(), True))\n",
    "tpFields.append(StructField('nconst', StringType(), True))\n",
    "tpFields.append(StructField('category', StringType(), True))\n",
    "tpFields.append(StructField('job', StringType(), True))\n",
    "tpFields.append(StructField('characters', StringType(), True))                     \n",
    "\n",
    "tpSchema = StructType(tpFields)\n",
    "\n",
    "#create df\n",
    "titlePrincipals_df = sqlContext.createDataFrame(titlePrincipals_rdd, tpSchema)\n",
    "\n",
    "#clean data\n",
    "titlePrincipals_df = titlePrincipals_df.filter(titlePrincipals_df.category.contains(\"actor\") | titlePrincipals_df.category.contains(\"actress\"))\n",
    "titlePrincipals_df = titlePrincipals_df.filter(titlePrincipals_df.characters !=\"\\\\N\")\n",
    "titlePrincipals_df = titlePrincipals_df.drop('job').sort('tconst', ascending=True)\n",
    "\n",
    "titlePrincipals_df.show(2, truncate = True)\n",
    "\n",
    "#write to csv file\n",
    "titlePrincipals_df.repartition(1).write.option(\"sep\", \"|\").format('com.databricks.spark.csv').save(outputFilepath + \"/titlePrincipals_df.csv\",header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------+\n",
      "|   tconst|averageRating|numVotes|\n",
      "+---------+-------------+--------+\n",
      "|tt0000001|          5.8|    1416|\n",
      "|tt0000002|          6.4|     167|\n",
      "+---------+-------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.RATINGS\n",
    "#tconst, averageRating, numVotes\n",
    "titleRatings_data = sc.textFile(filepath + '/IMDB/titleRatings.tsv')\n",
    "titleRatings_rdd = titleRatings_data.filter(lambda l: 'averageRating' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "trFields = []\n",
    "trFields.append(StructField('tconst', StringType(), True))\n",
    "trFields.append(StructField('averageRating', StringType(), True))\n",
    "trFields.append(StructField('numVotes', StringType(), True))                    \n",
    "\n",
    "trSchema = StructType(trFields)\n",
    "\n",
    "#create df\n",
    "titleRatings_df= sqlContext.createDataFrame(titleRatings_rdd, trSchema)\n",
    "\n",
    "titleRatings_df.show(2, truncate = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join title.Basics and title.Akas and title.Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+------+---------+---------+-------+--------------------+-------------+--------+\n",
      "|  titleId|            title|region|titleType|startYear|endYear|              genres|averageRating|numVotes|\n",
      "+---------+-----------------+------+---------+---------+-------+--------------------+-------------+--------+\n",
      "|tt0042899|   Ghost Mountain|    US|    movie|     1950|     \\N|Action,Adventure,...|          6.8|     791|\n",
      "|tt0042917|Salt Lake Raiders|    US|    movie|     1950|     \\N|             Western|          6.5|      59|\n",
      "|tt0043729|  Lawless Cowboys|    US|    movie|     1951|     \\N|             Western|          6.1|       9|\n",
      "+---------+-----------------+------+---------+---------+-------+--------------------+-------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Aliases\n",
    "Basics = titleBasics_df.alias('Basics')\n",
    "Akas = titleAkas_df.alias('Akas')\n",
    "Ratings = titleRatings_df.alias('Ratings')\n",
    "\n",
    "#join title.Basics to title.Akas\n",
    "AkasBasics = Akas.join(Basics, Akas.titleId == Basics.tconst, how='left')\n",
    "\n",
    "#clean data 1st join\n",
    "AkasBasics = AkasBasics.filter(AkasBasics.isAdult =='0')\n",
    "AkasBasics = AkasBasics.drop('ordering', 'language', 'types', \n",
    "                               'attributes', 'isOriginalTitle', 'tconst', \n",
    "                               'primaryTitle', 'isAdult')\n",
    "AkasBasics = AkasBasics.filter(AkasBasics.titleType.contains(\"movie\"))\n",
    "AkasBasics = AkasBasics.filter(AkasBasics.startYear >='1950')\n",
    "\n",
    "#join AkasBasics with title.Ratings\n",
    "titleABR = AkasBasics.join(Ratings, AkasBasics.titleId == Ratings.tconst, how='left')\n",
    "\n",
    "#clean data 2nd join\n",
    "titleABR = titleABR.drop('tconst')\n",
    "\n",
    "titleABR.show(3, truncate = True)\n",
    "\n",
    "#write to csv file\n",
    "titleABR.repartition(1).write.option(\"sep\", \"|\").format('com.databricks.spark.csv').save(outputFilepath + \"/titleABR.csv\", header = 'true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BabyNames\n",
    "## RDD Creation\n",
    "### US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#US Baby Names\n",
    "#NationalNames.csv\n",
    "#Id,Name,Year,Gender,Count\n",
    "nationalname_rdd_init = (sc.textFile(filepath + '/us-baby-names/NationalNames.csv'))\n",
    "nationalname_rdd = nationalname_rdd_init.filter(lambda x: 'Gender' not in x)\n",
    "nationalname_rdd = nationalname_rdd.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#State Baby Names\n",
    "#StateNames.csv\n",
    "#Id,Name,Year,Gender,State,Count\n",
    "full_statename_rdd_init = (sc.textFile(filepath + '/us-baby-names/StateNames.csv'))\n",
    "full_statename_rdd = full_statename_rdd_init.filter(lambda x: 'Gender' not in x).map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## US States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_states = {\n",
    "        'AK': 'Alaska',\n",
    "        'AL': 'Alabama',\n",
    "        'AR': 'Arkansas',\n",
    "        'AS': 'American Samoa',\n",
    "        'AZ': 'Arizona',\n",
    "        'CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut',\n",
    "        'DC': 'District of Columbia',\n",
    "        'DE': 'Delaware',\n",
    "        'FL': 'Florida',\n",
    "        'GA': 'Georgia',\n",
    "        'GU': 'Guam',\n",
    "        'HI': 'Hawaii',\n",
    "        'IA': 'Iowa',\n",
    "        'ID': 'Idaho',\n",
    "        'IL': 'Illinois',\n",
    "        'IN': 'Indiana',\n",
    "        'KS': 'Kansas',\n",
    "        'KY': 'Kentucky',\n",
    "        'LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts',\n",
    "        'MD': 'Maryland',\n",
    "        'ME': 'Maine',\n",
    "        'MI': 'Michigan',\n",
    "        'MN': 'Minnesota',\n",
    "        'MO': 'Missouri',\n",
    "        'MP': 'Northern Mariana Islands',\n",
    "        'MS': 'Mississippi',\n",
    "        'MT': 'Montana',\n",
    "        'NA': 'National',\n",
    "        'NC': 'North Carolina',\n",
    "        'ND': 'North Dakota',\n",
    "        'NE': 'Nebraska',\n",
    "        'NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey',\n",
    "        'NM': 'New Mexico',\n",
    "        'NV': 'Nevada',\n",
    "        'NY': 'New York',\n",
    "        'OH': 'Ohio',\n",
    "        'OK': 'Oklahoma',\n",
    "        'OR': 'Oregon',\n",
    "        'PA': 'Pennsylvania',\n",
    "        'PR': 'Puerto Rico',\n",
    "        'RI': 'Rhode Island',\n",
    "        'SC': 'South Carolina',\n",
    "        'SD': 'South Dakota',\n",
    "        'TN': 'Tennessee',\n",
    "        'TX': 'Texas',\n",
    "        'UT': 'Utah',\n",
    "        'VA': 'Virginia',\n",
    "        'VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont',\n",
    "        'WA': 'Washington',\n",
    "        'WI': 'Wisconsin',\n",
    "        'WV': 'West Virginia',\n",
    "        'WY': 'Wyoming'\n",
    "}\n",
    "us_states_abbreviations = list(us_states.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "## How many times does name x occur per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arwen\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~silkeh/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"Arwen\"\n",
    "\n",
    "def name_per_year_plot(name):\n",
    "    print(name)\n",
    "    pername_nationalname_rdd = nationalname_rdd.filter(lambda x: x[1] == str(name))\n",
    "    # Create a trace\n",
    "\n",
    "    trace = go.Scatter(\n",
    "        x = pername_nationalname_rdd.map(lambda x: int(x[2])).collect(),\n",
    "        y = pername_nationalname_rdd.map(lambda x: int(x[4])).collect()\n",
    "    )\n",
    "\n",
    "    data = [trace]\n",
    "\n",
    "    return(py.iplot(data, filename='basic-line'))\n",
    "\n",
    "name_per_year_plot(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 movies for year x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tt0042899', 'Ghost Mountain', 'US', 'movie', '1950', '\\\\N', 'Action,Adventure,Western', '6.8', '791'], ['tt0042917', 'Salt Lake Raiders', 'US', 'movie', '1950', '\\\\N', 'Western', '6.5', '59'], ['tt0043729', 'Lawless Cowboys', 'US', 'movie', '1951', '\\\\N', 'Western', '6.1', '9'], ['tt0043973', 'Roadblock', 'US', 'movie', '1951', '\\\\N', 'Crime,Drama,Film-Noir', '6.7', '869'], ['tt0044008', 'A Christmas Carol', 'US', 'movie', '1951', '\\\\N', 'Drama,Fantasy', '8.1', '17122'], ['tt0044083', 'The Strip', 'US', 'movie', '1951', '\\\\N', 'Crime,Drama,Film-Noir', '6.1', '509'], ['tt0044431', \"Damon Runyon's Bloodhounds of Broadway\", 'US', 'movie', '1952', '\\\\N', 'Comedy,Musical', '6.2', '193'], ['tt0044768', 'Desperate Decision', 'US', 'movie', '1952', '\\\\N', 'Drama', '6.5', '19'], ['tt0044770', 'Yolanda', 'US', 'movie', '1953', '\\\\N', 'Adventure', '6.8', '38'], ['tt0045015', 'Bombay Waterfront', 'US', 'movie', '1952', '\\\\N', 'Mystery', '5.9', '77']]\n",
      "[['tt0120737', 'The Lord of the Rings: The Fellowship of the Ring', 'US', 'movie', '2001', '\\\\N', 'Adventure,Drama,Fantasy', '8.8', '1440978'], ['tt0245429', \"Miyazaki's Spirited Away\", 'US', 'movie', '2001', '\\\\N', 'Adventure,Animation,Family', '8.6', '525036'], ['tt0211915', 'Amélie', 'US', 'movie', '2001', '\\\\N', 'Comedy,Romance', '8.3', '627539'], ['tt0292490', 'What the Heart Wants', 'US', 'movie', '2001', '\\\\N', 'Comedy,Drama,Romance', '8.2', '58531'], ['tt0268978', 'A Beautiful Mind', 'US', 'movie', '2001', '\\\\N', 'Biography,Drama', '8.2', '736720'], ['tt0169102', 'Taxation: Once Upon a Time in India', 'US', 'movie', '2001', '\\\\N', 'Adventure,Drama,Musical', '8.1', '88819'], ['tt0198781', 'Monsters, Inc. 3D', 'US', 'movie', '2001', '\\\\N', 'Adventure,Animation,Comedy', '8.1', '704436'], ['tt0246578', \"Donnie Darko: The Director's Cut\", 'US', 'movie', '2001', '\\\\N', 'Drama,Sci-Fi,Thriller', '8.1', '675485'], ['tt0293715', 'My Sassy Girl', 'US', 'movie', '2001', '\\\\N', 'Comedy,Drama,Romance', '8.1', '41172'], ['tt0166924', 'Mulholland Drive', 'US', 'movie', '2001', '\\\\N', 'Drama,Mystery,Thriller', '8.0', '279999']]\n"
     ]
    }
   ],
   "source": [
    "separator = '|'\n",
    "\n",
    "#create rdd\n",
    "titleABR_data = sc.textFile(filepath + '/IMDB_new/titleABR.csv/titleABR.csv')\n",
    "titleABR_rdd = titleABR_data.filter(lambda l: 'region' not in l).map(lambda l: l.split(separator))\n",
    "print(titleABR_rdd.take(10))\n",
    "\n",
    "#get top 10 movies by year\n",
    "top_movies_rdd = titleABR_rdd.filter(lambda x: x[4] == '2001').filter(lambda x: x[7] != '').filter(lambda x: ('Documentary') not in x[6]).filter(lambda x: float(x[8]) >99).sortBy(lambda x: float(x[7]), False)\n",
    "print(top_movies_rdd.take(10))\n",
    "#top_movies_list = top_movies_rdd.map(lambda x: x[0]).top(10)\n",
    "#print(top_movies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
