{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "import folium\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='silkeh', api_key='GwBAmaelgKfgkrmuL691')\n",
    "\n",
    "separator = '\\t'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB\n",
    "## Creation of RDD's and DF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TITLE.BASICS\n",
    "#tconst, titleType, primaryTitle, originalTitle, isAdult, startYear, endYear, runtimeMinutes, genres\n",
    "titleBasics_data = sc.textFile('D:/Workspace/_DataMining/DataSets/IMDB/titleBasics.tsv')\n",
    "titleBasics_rdd = titleBasics_data.filter(lambda l: 'primaryTitle' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "tbFields = []\n",
    "tbFields.append(StructField('tconst', StringType(), True))\n",
    "tbFields.append(StructField('titleType', StringType(), True))\n",
    "tbFields.append(StructField('primaryTitle', StringType(), True))\n",
    "tbFields.append(StructField('originalTitle', StringType(), True))\n",
    "tbFields.append(StructField('isAdult', StringType(), True))\n",
    "tbFields.append(StructField('startYear', StringType(), True))\n",
    "tbFields.append(StructField('endYear', StringType(), True))\n",
    "tbFields.append(StructField('runtimeMinutes', StringType(), True))\n",
    "tbFields.append(StructField('genres', StringType(), True))                           \n",
    "\n",
    "tbSchema = StructType(tbFields)\n",
    "\n",
    "#create df\n",
    "titleBasics_df= sqlContext.createDataFrame(titleBasics_rdd, tbSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TITLE.AKAS\n",
    "#tconst, ordering, title, region, language, types, attributes, isOriginalTitle\n",
    "titleAkas_data = sc.textFile('D:/Workspace/_DataMining/DataSets/IMDB/titleAkas.tsv')\n",
    "titleAkas_rdd = titleAkas_data.filter(lambda l: 'ordering' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "taFields = []\n",
    "taFields.append(StructField('titleId', StringType(), True))\n",
    "taFields.append(StructField('ordering', StringType(), True))\n",
    "taFields.append(StructField('title', StringType(), True))\n",
    "taFields.append(StructField('region', StringType(), True))\n",
    "taFields.append(StructField('language', StringType(), True))\n",
    "taFields.append(StructField('types', StringType(), True))\n",
    "taFields.append(StructField('attributes', StringType(), True))\n",
    "taFields.append(StructField('isOriginalTitle', StringType(), True))                       \n",
    "\n",
    "taSchema = StructType(taFields)\n",
    "\n",
    "#create df\n",
    "titleAkas_df= sqlContext.createDataFrame(titleAkas_rdd, taSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+--------+----------+\n",
      "|   tconst|ordering|   nconst|category|characters|\n",
      "+---------+--------+---------+--------+----------+\n",
      "|tt0199280|       7|nm0848894| actress| [\"Anita\"]|\n",
      "|tt0199282|       4|nm0036208| actress| [\"Meira\"]|\n",
      "+---------+--------+---------+--------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.PRINCIPALS\n",
    "#tconst, ordering, nconst, category, job, characters\n",
    "titlePrincipals_data = sc.textFile('D:/Workspace/_DataMining/DataSets/IMDB/titlePrincipals.tsv')\n",
    "titlePrincipals_rdd = titlePrincipals_data.filter(lambda l: 'ordering' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "tpFields = []\n",
    "tpFields.append(StructField('tconst', StringType(), True))\n",
    "tpFields.append(StructField('ordering', StringType(), True))\n",
    "tpFields.append(StructField('nconst', StringType(), True))\n",
    "tpFields.append(StructField('category', StringType(), True))\n",
    "tpFields.append(StructField('job', StringType(), True))\n",
    "tpFields.append(StructField('characters', StringType(), True))                     \n",
    "\n",
    "tpSchema = StructType(tpFields)\n",
    "\n",
    "#create df\n",
    "titlePrincipals_df = sqlContext.createDataFrame(titlePrincipals_rdd, tpSchema)\n",
    "\n",
    "titlePrincipals_df = titlePrincipals_df.filter(titlePrincipals_df.category.contains(\"actor\") | titlePrincipals_df.category.contains(\"actress\"))\n",
    "titlePrincipals_df = titlePrincipals_df.drop('job').sort('category', ascending=False)\n",
    " \n",
    "\n",
    "titlePrincipals_df.show(2, truncate = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+--------+\n",
      "|   tconst|averageRating|numVotes|\n",
      "+---------+-------------+--------+\n",
      "|tt0000001|          5.8|    1416|\n",
      "|tt0000002|          6.4|     167|\n",
      "+---------+-------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.RATINGS\n",
    "#tconst, averageRating, numVotes\n",
    "titleRatings_data = sc.textFile('D:/Workspace/_DataMining/DataSets/IMDB/titleRatings.tsv')\n",
    "titleRatings_rdd = titleRatings_data.filter(lambda l: 'averageRating' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "trFields = []\n",
    "trFields.append(StructField('tconst', StringType(), True))\n",
    "trFields.append(StructField('averageRating', StringType(), True))\n",
    "trFields.append(StructField('numVotes', StringType(), True))                    \n",
    "\n",
    "trSchema = StructType(trFields)\n",
    "\n",
    "#create df\n",
    "titleRatings_df= sqlContext.createDataFrame(titleRatings_rdd, trSchema)\n",
    "\n",
    "titleRatings_df.show(2, truncate = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------------+-------------+\n",
      "|   tconst|parentTconst|seasonNumber|episodeNumber|\n",
      "+---------+------------+------------+-------------+\n",
      "|tt0041951|   tt0041038|           1|            9|\n",
      "|tt0042816|   tt0989125|           1|           17|\n",
      "+---------+------------+------------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TITLE.EPISODE\n",
    "#tconst, parentTconst, seasonNumber, episodeNumber\n",
    "titleEpisode_data = sc.textFile('D:/Workspace/_DataMining/DataSets/IMDB/titleEpisode.tsv')\n",
    "titleEpisode_rdd = titleEpisode_data.filter(lambda l: 'seasonNumber' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "teFields = []\n",
    "teFields.append(StructField('tconst', StringType(), True))\n",
    "teFields.append(StructField('parentTconst', StringType(), True))\n",
    "teFields.append(StructField('seasonNumber', StringType(), True))\n",
    "teFields.append(StructField('episodeNumber', StringType(), True))                    \n",
    "\n",
    "teSchema = StructType(teFields)\n",
    "\n",
    "#create df\n",
    "titleEpisode_df= sqlContext.createDataFrame(titleEpisode_rdd, teSchema)\n",
    "\n",
    "titleEpisode_df.show(2, truncate = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+---------+--------------------+\n",
      "|   nconst|    primaryName|deathYear|   primaryProfession|\n",
      "+---------+---------------+---------+--------------------+\n",
      "|nm0000001|   Fred Astaire|     1987|soundtrack,actor,...|\n",
      "|nm0000002|  Lauren Bacall|     2014|  actress,soundtrack|\n",
      "|nm0000003|Brigitte Bardot|       \\N|actress,soundtrac...|\n",
      "|nm0000004|   John Belushi|     1982|actor,writer,soun...|\n",
      "|nm0000005| Ingmar Bergman|     2007|writer,director,a...|\n",
      "+---------+---------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NAME.BASICS\n",
    "#nconst, primaryName, birthYear, deathYear, primaryProfession, knownForTitles\n",
    "nameBasics_data = sc.textFile('D:/Workspace/_DataMining/DataSets/IMDB/nameBasics.tsv')\n",
    "nameBasics_rdd = nameBasics_data.filter(lambda l: 'primaryName' not in l).map(lambda l: l.split(separator))\n",
    "\n",
    "#create schema for df\n",
    "nmFields = []\n",
    "nmFields.append(StructField('nconst', StringType(), True))\n",
    "nmFields.append(StructField('primaryName', StringType(), True))\n",
    "nmFields.append(StructField('birthYear', StringType(), True))\n",
    "nmFields.append(StructField('deathYear', StringType(), True))\n",
    "nmFields.append(StructField('primaryProfession', StringType(), True))\n",
    "nmFields.append(StructField('knownForTitles', StringType(), True))\n",
    "\n",
    "nmSchema = StructType(nmFields)\n",
    "\n",
    "#create df\n",
    "nameBasics_df= sqlContext.createDataFrame(nameBasics_rdd, nmSchema)\n",
    "\n",
    "#nameBasics_df.show(1, truncate = True)\n",
    "\n",
    "nameBasics_df = nameBasics_df.drop('birthYear', 'knownForTitles')\n",
    "nameBasics_df = nameBasics_df.filter(nameBasics_df.primaryProfession.contains(\"actor\")|nameBasics_df.primaryProfession.contains(\"actress\")).sort('nconst', ascending=True)\n",
    "\n",
    "nameBasics_df.show(5, truncate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join title.Basics and title.Akas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------+---------+---------+-------+\n",
      "|  titleId|               title|region|titleType|startYear|endYear|\n",
      "+---------+--------------------+------+---------+---------+-------+\n",
      "|tt0000009|          Miss Jerry|    US|    movie|     1894|     \\N|\n",
      "|tt0000147|The Corbett-Fitzs...|    US|    movie|     1897|     \\N|\n",
      "|tt0000630|              Hamlet|    US|    movie|     1908|     \\N|\n",
      "+---------+--------------------+------+---------+---------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Aliases\n",
    "tB_df = titleBasics_df.alias('tB_df')\n",
    "tA_df = titleAkas_df.alias('tA_df')\n",
    "\n",
    "#filter title.Akas by region and distinct ID\n",
    "tA_df_Filtered = tA_df.filter(tA_df.region =='US')\n",
    "tA_df_Distinct = tA_df_Filtered.dropDuplicates(['titleId']).sort('titleId', ascending=True)\n",
    "\n",
    "#join title.Basics to title.Akas\n",
    "tA_Join_tB = tA_df_Distinct.join(tB_df, tA_df_Distinct.titleId == tB_df.tconst, how='left').sort('titleId', ascending=True)\n",
    "tA_Join_tB = tA_Join_tB.filter(tA_Join_tB.isAdult =='0')\n",
    "tA_Join_tB = tA_Join_tB.filter(tA_Join_tB.titleType.contains(\"movie\") | tA_Join_tB.titleType.contains(\"tvSeries\") | tA_Join_tB.titleType.contains(\"tvEpisode\"))\n",
    "\n",
    "#drop unnecessary columns\n",
    "tAtB_reduced = tA_Join_tB.drop('ordering', 'language', 'types', \n",
    "                               'attributes', 'isOriginalTitle', 'tconst', \n",
    "                               'primaryTitle', 'originalTitle', 'runtimeMinutes', \n",
    "                               'genres', 'isAdult')\n",
    "\n",
    "tAtB_reduced.show(3, truncate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join title.Ratings to AkasBasics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aliases\n",
    "AkasBasics = tAtB_reduced.alias('AkasBasics')\n",
    "Ratings = titleRatings_df.alias('Ratings')\n",
    "\n",
    "titleABR = AkasBasics.join(Ratings, AkasBasics.titleId == Ratings.tconst, how='left').sort('titleId', ascending=True)\n",
    "\n",
    "titleABR.show(3, truncate = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
